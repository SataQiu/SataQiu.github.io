<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="keywords" content="SataQiu, SataQiu`s Blog"><meta name="author" content="SataQiu"><meta name="description" content="Kubelet 垃圾回收原理剖析"><meta name="copyright" content="SataQiu"><title>Kubelet 垃圾回收原理剖析 | SataQiu`s Blog</title><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css"><link rel="stylesheet" href="/css/index.css?v=1.0.1"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-stun.png?v=1.0.1"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-stun.png?v=1.0.1"><script>var CONFIG = {
  back2top_animation: true,
  sidebar_offsetTop: '20px'
};
window.CONFIG = CONFIG;</script></head><body><div id="container"><header id="header" style="background-image: url(/images/background.jpg)"><nav class="header-nav"><div class="header-nav-inner"><div class="header-nav-menu-icon fa fa-bars"></div><div class="header-nav-search"><i class="fa fa-search"></i><span>搜索</span></div><div class="header-nav-menu"><span><a href="/"><i class="fa fa-home"></i>首页</a></span><span><a href="/archives/"><i class="fa fa-folder-open"></i>归档</a></span><span><a href="/categories/"><i class="fa fa-th"></i>分类</a></span><span><a href="/tags/"><i class="fa fa-tags"></i>标签</a></span><span><a href="/about/"><i class="fa fa-user"></i>关于</a></span></div></div></nav><div class="header-info"><div class="header-info-inner"><div class="site-info-title">SataQiu`s Blog</div><div class="site-info-subtitle"></div></div></div></header><main id="main"><div class="main-inner"><aside id="sidebar"><div class="sidebar-inner"><div class="sidebar-nav"><span class="sidebar-nav-toc current">文章目录</span><span class="sidebar-nav-overview">站点概览</span></div><section class="sidebar-toc"><div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#镜像回收"><span class="toc-number">1.</span> <span class="toc-text">镜像回收</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#主体流程"><span class="toc-number">1.1.</span> <span class="toc-text">主体流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#用户配置"><span class="toc-number">1.2.</span> <span class="toc-text">用户配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#实验环节"><span class="toc-number">1.3.</span> <span class="toc-text">实验环节</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#容器回收"><span class="toc-number">2.</span> <span class="toc-text">容器回收</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#主体流程-1"><span class="toc-number">2.1.</span> <span class="toc-text">主体流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#用户配置-1"><span class="toc-number">2.2.</span> <span class="toc-text">用户配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#实验环节-1"><span class="toc-number">2.3.</span> <span class="toc-text">实验环节</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#小结"><span class="toc-number">3.</span> <span class="toc-text">小结</span></a></li></ol></div></section><section class="hide sidebar-overview"><div class="sidebar-author"><img class="sidebar-author-avatar" src="/images/avatar.png" alt="avatar"></div><div class="sidebar-social"><span class="sidebar-social-item"><a href="https://github.com/SataQiu" target="_blank" title="github → https://github.com/SataQiu"><i class="fa fa-github"></i></a></span><span class="sidebar-social-item"><a href="https://blog.csdn.net/shida_csdn" target="_blank" title="csdn → https://blog.csdn.net/shida_csdn"><span>C</span></a></span><span class="sidebar-social-item"><a href="https://user.qzone.qq.com/1527062125" target="_blank" title="qq → https://user.qzone.qq.com/1527062125"><i class="fa fa-qq"></i></a></span></div><div class="sidebar-state"><div class="sidebar-state-item sidebar-state-posts"><a href="/archives/"><div class="sidebar-state-item-count">2</div><div class="sidebar-state-item-name">文章</div></a></div><div class="sidebar-state-item sidebar-state-categories"><a href="/categories/"><div class="sidebar-state-item-count">1</div><div class="sidebar-state-item-name">分类</div></a></div><div class="sidebar-state-item sidebar-state-tags"><a href="/tags/"><div class="sidebar-state-item-count">3</div><div class="sidebar-state-item-name">标签</div></a></div></div><div class="sidebar-cc"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh-cn" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="creative commons"></a></div></section><div class="sidebar-progress"><div class="sidebar-progress-read"><span>你已阅读了</span><span class="sidebar-progress-number"></span></div><div class="sidebar-progress-line"></div></div></div></aside><div class="main-content code-highlight"><div class="post-header"><h1 class="post-title">Kubelet 垃圾回收原理剖析</h1><div class="post-meta"><span class="post-meta-create"><i class="fa fa-calendar-o"></i><span>发表于 </span><span>2019-07-15</span></span><span class="post-meta-update"><i class="fa fa-calendar-check-o"></i><span>更新于 </span><span>2019-09-09</span></span><span class="post-meta-word-count"><i class="fa fa-file-word-o"></i><span>字数统计 </span><span>4k</span></span><span class="post-meta-reading-time"><i class="fa fa-clock-o"></i><span>阅读时长 </span><span>32 m</span></span><span class="post-meta-reading-count"><i class="fa fa-eye"></i><span>阅读次数 </span><span id="busuanzi_value_page_pv"></span></span></div></div><div class="post-body"><p>Kubelet 垃圾回收（Garbage Collection）是一个非常有用的功能，它负责自动清理节点上的无用镜像和容器。Kubelet 每隔 1 分钟进行一次容器清理，每隔 5 分钟进行一次镜像清理（截止到 v1.15 版本，垃圾回收间隔时间还都是在源码中固化的，不可自定义配置）。如果节点上已经运行了 Kubelet，不建议再额外运行其它的垃圾回收工具，因为这些工具可能错误地清理掉 Kubelet 认为本应保留的镜像或容器，从而可能造成不可预知的问题。</p>
<a id="more"></a>

<h2 id="镜像回收"><a href="#镜像回收" class="headerlink" title="镜像回收"></a>镜像回收</h2><p>Kubernetes 对节点上的所有镜像提供生命周期管理服务，这里的『所有镜像』是真正意义上的所有镜像，而不仅仅是通过 Kubelet 拉取的镜像。当磁盘使用率超过设定上限（<code>HighThresholdPercent</code>）时，Kubelet 就会按照 LRU 清除策略逐个清理掉那些没有被任何 Pod 容器（包括那些已经死亡的容器）所使用的镜像，直到磁盘使用率降到设定下限（<code>LowThresholdPercent</code>）或没有空闲镜像可以清理。此外，在进行镜像清理时，会考虑镜像的生存年龄，对于年龄没有达到最短生存年龄（<code>MinAge</code>）要求的镜像，暂不予以清理。</p>
<h3 id="主体流程"><a href="#主体流程" class="headerlink" title="主体流程"></a>主体流程</h3><p><img src="/assets/k8s-kubelet-gc/image-gc-workflow.svg" alt></p>
<p>如上图所示，Kubelet 对于节点上镜像的回收流程还是比较简单的，在磁盘使用率超出设定上限后：首先，通过 CRI 容器运行时接口读取节点上的所有镜像以及 Pod 容器；然后，根据现有容器列表过滤出那些已经不被任何容器所使用的镜像；接着，按照镜像最近被使用时间排序，越久被用到的镜像越会被排在前面，优先清理；最后，就按照排好的顺序逐个清理镜像，直到磁盘使用率降到设定下限（或者已经没有空闲镜像可以清理）。</p>
<p>需要注意的是，Kubelet 读取到的镜像列表是节点镜像列表，而读取到的容器列表却仅包括由其管理的容器（即 Pod 容器，包括 Pod 内的死亡容器）。因此，那些用户手动 <code>run</code> 起来的容器，对于 Kubelet 垃圾回收来说就是不可见的，也就不能阻止对相关镜像的垃圾回收。当然，Kubelet 的镜像回收不是 force 类型的回收，虽然会对用户手动下载的镜像进行回收动作，但如果确实有运行的（或者停止的任何）容器与该镜像关联的话，删除操作就会失败（被底层容器运行时阻止删除）。</p>
<h3 id="用户配置"><a href="#用户配置" class="headerlink" title="用户配置"></a>用户配置</h3><p>通过上面的分析，我们知道影响镜像垃圾回收的关键参数有：</p>
<p><code>image-gc-high-threshold</code>：磁盘使用率上限，有效范围 [0-100]，默认 <code>85</code></p>
<p><code>image-gc-low-threshold</code>：磁盘使用率下限，有效范围 [0-100]，默认 <code>80</code></p>
<p><code>minimum-image-ttl-duration</code>：镜像最短应该生存的年龄，默认 <code>2</code> 分钟</p>
<h3 id="实验环节"><a href="#实验环节" class="headerlink" title="实验环节"></a>实验环节</h3><p>本节我们通过实验来验证镜像垃圾回收（基于 Kubelet 1.15 版本）。</p>
<p>实验前，需要配置 Kubelet 启动参数，降低磁盘使用率上限，以便能够直接触发镜像回收。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vim /etc/systemd/system/kubelet.service.d/10-kubeadm.conf</span></span><br><span class="line">...</span><br><span class="line">ExecStart=/usr/bin/kubelet <span class="variable">$KUBELET_KUBECONFIG_ARGS</span> <span class="variable">$KUBELET_CONFIG_ARGS</span> <span class="variable">$KUBELET_KUBEADM_ARGS</span> <span class="variable">$KUBELET_EXTRA_ARGS</span> --image-gc-high-threshold=2 --image-gc-low-threshold=1</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>我们在 Kubelet 启动参数的最后追加了 <code>--image-gc-high-threshold=2 --image-gc-low-threshold=1</code>，这么低的配置，Kubelet 应该会一直忙于进行镜像回收了，生产环境可不能这么配置！</p>
<p>执行以下命令使得配置生效：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># systemctl daemon-reload</span></span><br><span class="line"><span class="comment"># systemctl restart kubelet</span></span><br></pre></td></tr></table></figure>

<p>首先，看下本地都有哪些镜像：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">root@shida-machine:~<span class="comment"># docker images</span></span><br><span class="line">REPOSITORY                           TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">k8s.gcr.io/kube-proxy                v1.14.4             5f2081c22306        6 days ago          82.1MB</span><br><span class="line">k8s.gcr.io/kube-apiserver            v1.14.4             f3171d49fa9b        6 days ago          210MB</span><br><span class="line">k8s.gcr.io/kube-controller-manager   v1.14.4             35f0904dc8fa        6 days ago          158MB</span><br><span class="line">k8s.gcr.io/kube-scheduler            v1.14.4             ee080c083e45        6 days ago          81.6MB</span><br><span class="line">calico/node                          v3.7.3              bf4ff15c9db0        4 weeks ago         156MB</span><br><span class="line">calico/cni                           v3.7.3              1a6ade52d471        4 weeks ago         135MB</span><br><span class="line">calico/kube-controllers              v3.7.3              283860d96794        4 weeks ago         46.8MB</span><br><span class="line">k8s.gcr.io/coredns                   1.3.1               eb516548c180        6 months ago        40.3MB</span><br><span class="line">k8s.gcr.io/etcd                      3.3.10              2c4adeb21b4f        7 months ago        258MB</span><br><span class="line">k8s.gcr.io/pause                     3.1                 da86e6ba6ca1        19 months ago       742kB</span><br></pre></td></tr></table></figure>

<p>接下来，我们运行一个 <code>nginx</code> 程序，让 Kubelet 自动拉取镜像。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">root@shida-machine:~<span class="comment"># kubectl run nginx --image=nginx</span></span><br><span class="line">deployment.apps/nginx created</span><br><span class="line">root@shida-machine:~<span class="comment"># kubectl get deployment</span></span><br><span class="line">NAME    READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">nginx   1/1     1            1           62s</span><br><span class="line">root@shida-machine:~<span class="comment"># docker images</span></span><br><span class="line">REPOSITORY                           TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">k8s.gcr.io/kube-proxy                v1.14.4             5f2081c22306        6 days ago          82.1MB</span><br><span class="line">k8s.gcr.io/kube-controller-manager   v1.14.4             35f0904dc8fa        6 days ago          158MB</span><br><span class="line">k8s.gcr.io/kube-apiserver            v1.14.4             f3171d49fa9b        6 days ago          210MB</span><br><span class="line">k8s.gcr.io/kube-scheduler            v1.14.4             ee080c083e45        6 days ago          81.6MB</span><br><span class="line">nginx                                latest              f68d6e55e065        12 days ago         109MB</span><br><span class="line">calico/node                          v3.7.3              bf4ff15c9db0        4 weeks ago         156MB</span><br><span class="line">calico/cni                           v3.7.3              1a6ade52d471        4 weeks ago         135MB</span><br><span class="line">calico/kube-controllers              v3.7.3              283860d96794        4 weeks ago         46.8MB</span><br><span class="line">k8s.gcr.io/coredns                   1.3.1               eb516548c180        6 months ago        40.3MB</span><br><span class="line">k8s.gcr.io/etcd                      3.3.10              2c4adeb21b4f        7 months ago        258MB</span><br><span class="line">k8s.gcr.io/pause                     3.1                 da86e6ba6ca1        19 months ago       742kB</span><br></pre></td></tr></table></figure>

<p>可以看到，<code>nginx</code> 镜像已经被自动 <code>pull</code> 到本地了，ID 为 <code>f68d6e55e065</code>。</p>
<p>然后，删除 <code>nginx</code> Deployment：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@shida-machine:~<span class="comment"># kubectl delete deployment nginx</span></span><br><span class="line">deployment.extensions <span class="string">"nginx"</span> deleted</span><br></pre></td></tr></table></figure>

<p>过大概 5 分钟后，再次检查本地镜像列表，发现 <code>nginx</code> 镜像已被清理！</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">root@shida-machine:~<span class="comment"># docker images</span></span><br><span class="line">REPOSITORY                           TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">k8s.gcr.io/kube-proxy                v1.14.4             5f2081c22306        6 days ago          82.1MB</span><br><span class="line">k8s.gcr.io/kube-controller-manager   v1.14.4             35f0904dc8fa        6 days ago          158MB</span><br><span class="line">k8s.gcr.io/kube-apiserver            v1.14.4             f3171d49fa9b        6 days ago          210MB</span><br><span class="line">k8s.gcr.io/kube-scheduler            v1.14.4             ee080c083e45        6 days ago          81.6MB</span><br><span class="line">calico/node                          v3.7.3              bf4ff15c9db0        4 weeks ago         156MB</span><br><span class="line">calico/cni                           v3.7.3              1a6ade52d471        4 weeks ago         135MB</span><br><span class="line">calico/kube-controllers              v3.7.3              283860d96794        4 weeks ago         46.8MB</span><br><span class="line">k8s.gcr.io/coredns                   1.3.1               eb516548c180        6 months ago        40.3MB</span><br><span class="line">k8s.gcr.io/etcd                      3.3.10              2c4adeb21b4f        7 months ago        258MB</span><br><span class="line">k8s.gcr.io/pause                     3.1                 da86e6ba6ca1        19 months ago       742kB</span><br></pre></td></tr></table></figure>

<p>通过以下命令查看镜像垃圾回收日志：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@shida-machine:~<span class="comment"># journalctl -u kubelet -o cat | grep imageGCManager</span></span><br><span class="line">...</span><br><span class="line">I0714 18:03:20.883489   51179 image_gc_manager.go:300] [imageGCManager]: Disk usage on image filesystem is at 24% <span class="built_in">which</span> is over the high threshold (2%). Trying to free 72470076620 bytes down to the low threshold (1%).</span><br><span class="line">I0714 18:03:20.899370   51179 image_gc_manager.go:371] [imageGCManager]: Removing image <span class="string">"sha256:f68d6e55e06520f152403e6d96d0de5c9790a89b4cfc99f4626f68146fa1dbdc"</span> to free 109357355 bytes</span><br></pre></td></tr></table></figure>

<p>可以看到，日志中记录的删除镜像 ID 与 <code>nginx</code> 镜像的 ID 是一致的（均为 <code>f68d6e55e065</code>）。</p>
<p>继续验证用户手动拉取的镜像是否会被清理，手动运行 <code>nginx</code> 程序：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">root@shida-machine:~<span class="comment"># docker run --name nginx -d nginx </span></span><br><span class="line">Unable to find image <span class="string">'nginx:latest'</span> locally</span><br><span class="line">latest: Pulling from library/nginx</span><br><span class="line">fc7181108d40: Pull complete </span><br><span class="line">d2e987ca2267: Pull complete </span><br><span class="line">0b760b431b11: Pull complete </span><br><span class="line">Digest: sha256:48cbeee0cb0a3b5e885e36222f969e0a2f41819a68e07aeb6631ca7cb356fed1</span><br><span class="line">Status: Downloaded newer image <span class="keyword">for</span> nginx:latest</span><br><span class="line">2fc8a836ba3c7cbd488c7fd4f2ffa7287b709abf1b7701685291c3b1e5df3472</span><br></pre></td></tr></table></figure>

<p>通过查看镜像 GC 日志，会发现 GC 会尝试清理用户自己手动拉取的 <code>nginx</code> 镜像，但因为该镜像被使用中，所以这次删除操作不会成功：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">root@shida-machine:~<span class="comment"># journalctl -u kubelet -o cat | grep imageGCManager</span></span><br><span class="line">...</span><br><span class="line">I0714 18:28:23.015586   51179 image_gc_manager.go:300] [imageGCManager]: Disk usage on image filesystem is at 24% <span class="built_in">which</span> is over the high threshold (2%). Trying to free 72501525708 bytes down to the low threshold (1%).</span><br><span class="line">I0714 18:28:23.306696   51179 image_gc_manager.go:371] [imageGCManager]: Removing image <span class="string">"sha256:f68d6e55e06520f152403e6d96d0de5c9790a89b4cfc99f4626f68146fa1dbdc"</span> to free 109357355 bytes</span><br><span class="line">root@shida-machine:~<span class="comment"># docker images</span></span><br><span class="line">REPOSITORY                           TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">k8s.gcr.io/kube-proxy                v1.14.4             5f2081c22306        6 days ago          82.1MB</span><br><span class="line">k8s.gcr.io/kube-apiserver            v1.14.4             f3171d49fa9b        6 days ago          210MB</span><br><span class="line">k8s.gcr.io/kube-controller-manager   v1.14.4             35f0904dc8fa        6 days ago          158MB</span><br><span class="line">k8s.gcr.io/kube-scheduler            v1.14.4             ee080c083e45        6 days ago          81.6MB</span><br><span class="line">nginx                                latest              f68d6e55e065        12 days ago         109MB</span><br><span class="line">calico/node                          v3.7.3              bf4ff15c9db0        4 weeks ago         156MB</span><br><span class="line">calico/cni                           v3.7.3              1a6ade52d471        4 weeks ago         135MB</span><br><span class="line">calico/kube-controllers              v3.7.3              283860d96794        4 weeks ago         46.8MB</span><br><span class="line">k8s.gcr.io/coredns                   1.3.1               eb516548c180        6 months ago        40.3MB</span><br><span class="line">k8s.gcr.io/etcd                      3.3.10              2c4adeb21b4f        7 months ago        258MB</span><br><span class="line">k8s.gcr.io/pause                     3.1                 da86e6ba6ca1        19 months ago       742kB</span><br></pre></td></tr></table></figure>

<p>将该容器停止，继续观察回收动作：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">root@shida-machine:~<span class="comment"># docker stop nginx</span></span><br><span class="line">nginx</span><br><span class="line">root@shida-machine:~<span class="comment"># journalctl -u kubelet -o cat | grep imageGCManager</span></span><br><span class="line">...</span><br><span class="line">I0714 18:53:23.579629   51179 image_gc_manager.go:300] [imageGCManager]: Disk usage on image filesystem is at 24% <span class="built_in">which</span> is over the high threshold (2%). Trying to free 72549280972 bytes down to the low threshold (1%).</span><br><span class="line">I0714 18:53:23.629492   51179 image_gc_manager.go:371] [imageGCManager]: Removing image <span class="string">"sha256:f68d6e55e06520f152403e6d96d0de5c9790a89b4cfc99f4626f68146fa1dbdc"</span> to free 109357355 bytes</span><br><span class="line">root@shida-machine:~<span class="comment"># docker images</span></span><br><span class="line">REPOSITORY                           TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">k8s.gcr.io/kube-proxy                v1.14.4             5f2081c22306        6 days ago          82.1MB</span><br><span class="line">k8s.gcr.io/kube-controller-manager   v1.14.4             35f0904dc8fa        6 days ago          158MB</span><br><span class="line">k8s.gcr.io/kube-apiserver            v1.14.4             f3171d49fa9b        6 days ago          210MB</span><br><span class="line">k8s.gcr.io/kube-scheduler            v1.14.4             ee080c083e45        6 days ago          81.6MB</span><br><span class="line">nginx                                latest              f68d6e55e065        12 days ago         109MB</span><br><span class="line">calico/node                          v3.7.3              bf4ff15c9db0        4 weeks ago         156MB</span><br><span class="line">calico/cni                           v3.7.3              1a6ade52d471        4 weeks ago         135MB</span><br><span class="line">calico/kube-controllers              v3.7.3              283860d96794        4 weeks ago         46.8MB</span><br><span class="line">k8s.gcr.io/coredns                   1.3.1               eb516548c180        6 months ago        40.3MB</span><br><span class="line">k8s.gcr.io/etcd                      3.3.10              2c4adeb21b4f        7 months ago        258MB</span><br><span class="line">k8s.gcr.io/pause                     3.1                 da86e6ba6ca1        19 months ago       742kB</span><br></pre></td></tr></table></figure>

<p>可以看到，对于已经停止的容器，Kubelet 也是会尝试删除，但删除操作依然不会成功（存在死亡容器对该镜像的引用）。</p>
<p>彻底删除 <code>nginx</code> 容器，此时就没有任何容器继续使用该镜像，经过 1 次 GC 后，<code>nginx</code> 镜像就会被清理。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">root@shida-machine:~<span class="comment"># docker rm nginx</span></span><br><span class="line">nginx</span><br><span class="line">root@shida-machine:~<span class="comment"># docker images</span></span><br><span class="line">REPOSITORY                           TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">k8s.gcr.io/kube-proxy                v1.14.4             5f2081c22306        6 days ago          82.1MB</span><br><span class="line">k8s.gcr.io/kube-apiserver            v1.14.4             f3171d49fa9b        6 days ago          210MB</span><br><span class="line">k8s.gcr.io/kube-controller-manager   v1.14.4             35f0904dc8fa        6 days ago          158MB</span><br><span class="line">k8s.gcr.io/kube-scheduler            v1.14.4             ee080c083e45        6 days ago          81.6MB</span><br><span class="line">calico/node                          v3.7.3              bf4ff15c9db0        4 weeks ago         156MB</span><br><span class="line">calico/cni                           v3.7.3              1a6ade52d471        4 weeks ago         135MB</span><br><span class="line">calico/kube-controllers              v3.7.3              283860d96794        4 weeks ago         46.8MB</span><br><span class="line">k8s.gcr.io/coredns                   1.3.1               eb516548c180        6 months ago        40.3MB</span><br><span class="line">k8s.gcr.io/etcd                      3.3.10              2c4adeb21b4f        7 months ago        258MB</span><br><span class="line">k8s.gcr.io/pause                     3.1                 da86e6ba6ca1        19 months ago       742kB</span><br></pre></td></tr></table></figure>

<h2 id="容器回收"><a href="#容器回收" class="headerlink" title="容器回收"></a>容器回收</h2><p>了解了镜像回收的基本原理，我们再来看看容器回收。容器在停止运行（比如出错退出或者正常结束）后会残留一系列的垃圾文件，一方面会占据磁盘空间，另一方面也会影响系统运行速度。此时，就需要 Kubelet 容器回收了。要特别注意的是，Kubelet 回收的容器是指那些由其管理的的容器（也就是 Pod 容器），用户手动运行的容器不会被 Kubelet 进行垃圾回收。</p>
<p>与容器垃圾回收相关的控制参数主要有 3 个：</p>
<p><code>MinAge</code>：容器可以被执行垃圾回收的最小年龄</p>
<p><code>MaxPerPodContainer</code>：每个 pod 内允许存在的死亡容器的最大数量</p>
<p><code>MaxContainers</code>：节点上全部死亡容器的最大数量</p>
<blockquote>
<p>注意：当 <code>MaxPerPodContainer</code> 与 <code>MaxContainers</code> 发生冲突时，Kubelet 会自动调整 <code>MaxPerPodContainer</code> 的取值以满足 <code>MaxContainers</code> 要求。</p>
</blockquote>
<h3 id="主体流程-1"><a href="#主体流程-1" class="headerlink" title="主体流程"></a>主体流程</h3><p><img src="/assets/k8s-kubelet-gc/container-gc-workflow.svg" alt></p>
<p>容器回收主要针对三个目标资源：普通容器、sandbox 容器以及容器日志目录。</p>
<p>对于普通容器，主要根据 <code>MaxPerPodContainer</code> 与 <code>MaxContainers</code> 的设置，按照 LRU 策略，从 Pod 的死亡容器列表删除一定数量的容器，直到满足配置需求；对于 <code>sandbox</code> 容器，按照每个 Pod 保留一个的原则清理多余的死亡 <code>sandbox</code>；对于日志目录，只要没有 Pod 与之关联了就将其删除。</p>
<p>Kubelet 的容器垃圾回收只针对 Pod 容器，非 Kubelet Pod 容器（比如通过 <code>docker run</code> 启动的容器）不会被主动清理。</p>
<h3 id="用户配置-1"><a href="#用户配置-1" class="headerlink" title="用户配置"></a>用户配置</h3><p>影响容器垃圾回收的关键参数有：</p>
<p><code>minimum-container-ttl-duration</code>：容器可被回收的最小生存年龄，默认是 <code>0</code> 分钟，这意味着每个死亡容器都会被立即执行垃圾回收</p>
<p><code>maximum-dead-containers-per-container</code>：每个 Pod 要保留的死亡容器的最大数量，默认值为 <code>1</code></p>
<p><code>maximum-dead-containers</code>：节点可保留的死亡容器的最大数量，默认值是 <code>-1</code>，这意味着节点没有限制死亡容器数量</p>
<h3 id="实验环节-1"><a href="#实验环节-1" class="headerlink" title="实验环节"></a>实验环节</h3><p>还是以 <code>nginx</code> 为例，创建一个 <code>nginx</code> 服务：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">root@shida-machine:~<span class="comment"># kubectl run nginx --image nginx</span></span><br><span class="line">deployment.apps/nginx created</span><br><span class="line">root@shida-machine:~<span class="comment"># docker ps -a | grep nginx</span></span><br><span class="line">7bef0308d9ea        nginx                     <span class="string">"nginx -g 'daemon of…"</span>   16 seconds ago      Up 14 seconds                                 k8s_nginx_nginx-7db9fccd9b-p2p2t_default_69c38c2b-a64e-11e9-94bd-000c29ce064a_0</span><br><span class="line">7e65e0db52c2        k8s.gcr.io/pause:3.1      <span class="string">"/pause"</span>                 2 minutes ago       Up 2 minutes                                  k8s_POD_nginx-7db9fccd9b-p2p2t_default_69c38c2b-a64e-11e9-94bd-000c29ce064a_0</span><br></pre></td></tr></table></figure>

<p>可以看到，Kubelet 启动了一个 <code>sandbox</code> 以及一个 <code>nginx</code> 实例。</p>
<p>手动杀死 <code>nginx</code> 实例，模拟容器异常退出：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">root@shida-machine:~<span class="comment"># docker kill 7bef0308d9ea</span></span><br><span class="line">7bef0308d9ea</span><br><span class="line">root@shida-machine:~<span class="comment"># docker ps -a | grep nginx</span></span><br><span class="line">408b23b2b72a        nginx                     <span class="string">"nginx -g 'daemon of…"</span>   3 seconds ago       Up 2 seconds                                      k8s_nginx_nginx-7db9fccd9b-p2p2t_default_69c38c2b-a64e-11e9-94bd-000c29ce064a_1</span><br><span class="line">7bef0308d9ea        nginx                     <span class="string">"nginx -g 'daemon of…"</span>   2 minutes ago       Exited (137) 15 seconds ago                       k8s_nginx_nginx-7db9fccd9b-p2p2t_default_69c38c2b-a64e-11e9-94bd-000c29ce064a_0</span><br><span class="line">7e65e0db52c2        k8s.gcr.io/pause:3.1      <span class="string">"/pause"</span>                 5 minutes ago       Up 5 minutes                                      k8s_POD_nginx-7db9fccd9b-p2p2t_default_69c38c2b-a64e-11e9-94bd-000c29ce064a_0</span><br></pre></td></tr></table></figure>

<p>可以看到 Kubelet 重新拉起了一个新的 <code>nginx</code> 实例。</p>
<p>等待几分钟，发现 Kubelet 并未清理异常退出的 <code>nginx</code> 容器（因为此时仅有一个 dead container）。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@shida-machine:~<span class="comment"># docker ps -a | grep nginx</span></span><br><span class="line">408b23b2b72a        nginx                     <span class="string">"nginx -g 'daemon of…"</span>   3 minutes ago       Up 3 minutes                                     k8s_nginx_nginx-7db9fccd9b-p2p2t_default_69c38c2b-a64e-11e9-94bd-000c29ce064a_1</span><br><span class="line">7bef0308d9ea        nginx                     <span class="string">"nginx -g 'daemon of…"</span>   5 minutes ago       Exited (137) 3 minutes ago                       k8s_nginx_nginx-7db9fccd9b-p2p2t_default_69c38c2b-a64e-11e9-94bd-000c29ce064a_0</span><br><span class="line">7e65e0db52c2        k8s.gcr.io/pause:3.1      <span class="string">"/pause"</span>                 8 minutes ago       Up 8 minutes                                     k8s_POD_nginx-7db9fccd9b-p2p2t_default_69c38c2b-a64e-11e9-94bd-000c29ce064a_0</span><br></pre></td></tr></table></figure>

<p>继续杀死当前 <code>nginx</code> 实例：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">root@shida-machine:~<span class="comment"># docker kill 408b23b2b72a</span></span><br><span class="line">408b23b2b72a</span><br><span class="line">root@shida-machine:~<span class="comment"># docker ps -a | grep nginx</span></span><br><span class="line">e064e376819f        nginx                     <span class="string">"nginx -g 'daemon of…"</span>   9 seconds ago       Up 7 seconds                                      k8s_nginx_nginx-7db9fccd9b-p2p2t_default_69c38c2b-a64e-11e9-94bd-000c29ce064a_2</span><br><span class="line">408b23b2b72a        nginx                     <span class="string">"nginx -g 'daemon of…"</span>   5 minutes ago       Exited (137) 40 seconds ago                       k8s_nginx_nginx-7db9fccd9b-p2p2t_default_69c38c2b-a64e-11e9-94bd-000c29ce064a_1</span><br><span class="line">7e65e0db52c2        k8s.gcr.io/pause:3.1      <span class="string">"/pause"</span>                 10 minutes ago      Up 10 minutes                                     k8s_POD_nginx-7db9fccd9b-p2p2t_default_69c38c2b-a64e-11e9-94bd-000c29ce064a_0</span><br></pre></td></tr></table></figure>

<p>这下看到效果了，仍然只有一个退出的容器被保留，而且被清理掉的是最老的死亡容器，这与之前的分析是一致的！</p>
<p>删除这个 <code>nginx</code> Deployment，会发现所有的 <code>nginx</code> 容器都会被清理：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@shida-machine:~<span class="comment"># kubectl delete deployment nginx</span></span><br><span class="line">deployment.extensions <span class="string">"nginx"</span> deleted</span><br><span class="line">root@shida-machine:~<span class="comment"># docker ps -a | grep nginx</span></span><br><span class="line">root@shida-machine:~<span class="comment">#</span></span><br></pre></td></tr></table></figure>

<p>进一步，我们修改 Kubelet 参数，设置 <code>maximum-dead-containers</code> 为 <code>0</code>，这就告诉 Kubelet 清理所有死亡容器。</p>
<p>重复前边的实验步骤：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">root@shida-machine:~<span class="comment"># kubectl run nginx --image nginx</span></span><br><span class="line">deployment.apps/nginx created</span><br><span class="line">root@shida-machine:~<span class="comment"># docker ps -a | grep nginx</span></span><br><span class="line">8de9ae8e2c9b        nginx                     <span class="string">"nginx -g 'daemon of…"</span>   33 seconds ago      Up 32 seconds                                   k8s_nginx_nginx-7db9fccd9b-jl2xn_default_0cd67a29-a6a2-11e9-94bd-000c29ce064a_0</span><br><span class="line">d2cdfafdbe50        k8s.gcr.io/pause:3.1      <span class="string">"/pause"</span>                 41 seconds ago      Up 38 seconds                                   k8s_POD_nginx-7db9fccd9b-jl2xn_default_0cd67a29-a6a2-11e9-94bd-000c29ce064a_0</span><br><span class="line">root@shida-machine:~<span class="comment"># docker kill 8de9ae8e2c9b</span></span><br><span class="line">8de9ae8e2c9b</span><br><span class="line">root@shida-machine:~<span class="comment"># docker ps -a | grep nginx</span></span><br><span class="line">95ee5bd2cab2        nginx                     <span class="string">"nginx -g 'daemon of…"</span>   About a minute ago   Up About a minute                             k8s_nginx_nginx-7db9fccd9b-jl2xn_default_0cd67a29-a6a2-11e9-94bd-000c29ce064a_1</span><br><span class="line">d2cdfafdbe50        k8s.gcr.io/pause:3.1      <span class="string">"/pause"</span>                 2 minutes ago        Up About a minute                             k8s_POD_nginx-7db9fccd9b-jl2xn_default_0cd67a29-a6a2-11e9-94bd-000c29ce064a_0</span><br></pre></td></tr></table></figure>

<p>结果显示，<code>nginx</code> Pod 的所有死亡容器都会被清理，因为我们已经强制要求节点不保留任何死亡容器，与预期一致！</p>
<p>那对于手动运行的容器呢？我们通过 <code>docker run</code> 运行 <code>nginx</code>：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@shida-machine:~<span class="comment"># docker run --name nginx -d nginx</span></span><br><span class="line">46ebb365f6be060a6950f44728e4f11e4666bf2fb007cad557ffc65ecf8aded8</span><br><span class="line">root@shida-machine:~<span class="comment"># docker ps | grep nginx</span></span><br><span class="line">46ebb365f6be        nginx                     <span class="string">"nginx -g 'daemon of…"</span>   9 seconds ago       Up 6 seconds        80/tcp              nginx</span><br></pre></td></tr></table></figure>

<p>杀死该容器：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@shida-machine:~<span class="comment"># docker kill 46ebb365f6be</span></span><br><span class="line">46ebb365f6be</span><br><span class="line">root@shida-machine:~<span class="comment"># docker ps -a | grep nginx</span></span><br><span class="line">46ebb365f6be        nginx                     <span class="string">"nginx -g 'daemon of…"</span>   About a minute ago   Exited (137) 18 seconds ago                       nginx</span><br></pre></td></tr></table></figure>

<p>经过几分钟，我们发现该死亡容器还是会存在的，Kubelet 不会清理这类容器！</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>Kubelet 每 5 分钟进行一次镜像清理。当磁盘使用率超过上限阈值，Kubelet 会按照 LRU 策略逐一清理没有被任何容器所使用的镜像，直到磁盘使用率降到下限阈值或没有空闲镜像可以清理。Kubelet 认为镜像可被清理的标准是未被任何 Pod 容器（包括那些死亡了的容器）所引用，那些非 Pod 容器（如用户通过 <code>docker run</code> 启动的容器）是不会被用来计算镜像引用关系的。也就是说，即便用户运行的容器使用了 A 镜像，只要没有任何 Pod 容器使用到 A，那 A 镜像对于 Kubelet 而言就是可被回收的。但是我们无需担心手动运行容器使用的镜像会被意外回收，因为 Kubelet 的镜像删除是非 force 类型的，底层容器运行时会使存在容器关联的镜像删除操作失败（因为 Docker 会认为仍有容器使用着 A 镜像）。</p>
<p>Kubelet 每 1 分钟执行一次容器清理。根据启动配置参数，Kubelet 会按照 LRU 策略依次清理每个 Pod 内的死亡容器，直到达到死亡容器限制数要求，对于 <code>sandbox</code> 容器，Kubelet 仅会保留最新的（这不受 GC 策略的控制）。对于日志目录，只要已经没有 Pod 继续占用，就将其清理。对于非 Pod 容器（如用户通过 <code>docker run</code> 启动的容器）不会被 Kubelet 垃圾回收。</p>
</div><footer class="post-footer"><div class="post-footer-end"><span>------</span><span>本文结束，感谢您的阅读</span><span>------</span></div><div class="post-footer-copyright"><div class="copyright-author"><span class="copyright-name">本文作者:</span><span class="copyright-value"><a href="https://SataQiu.github.io">SataQiu</a></span></div><div class="copyright-link"><span class="copyright-name">本文链接:</span><span class="copyright-value"><a href="https://SataQiu.github.io/2019/07/15/k8s-kubelet-gc/">https://SataQiu.github.io/2019/07/15/k8s-kubelet-gc/</a></span></div><div class="copyright-notice"><span class="copyright-name">版权声明:</span><span class="copyright-value">本博客所有文章除特别声明外，均采用  <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh-cn" rel="external nofollow" target="_blank">BY-NC-SA</a> 许可协议。转载请注明出处！</span></div></div><div class="post-footer-tags"><i class="fa fa-tags icon"></i><span><a href="https://SataQiu.github.io/tags/kubelet/" title="kubelet">kubelet</a></span><span><a href="https://SataQiu.github.io/tags/gc/" title="gc">gc</a></span></div><nav id="paginator"><div class="post-paginator"><div class="article-prev pull-left"><a href="/2019/09/09/architecting-kubernetes-clusters-choosing-a-worker-node-size/"><i class="fa fa-chevron-left"></i><span class="title">K8s 集群规划之节点资源配置</span></a></div></div></nav></footer></div><div class="comments main-content-layout" id="comments"><div id="gitment-container"></div></div></div></main><footer id="footer"><div class="footer-inner"><div class="busuanzi"><script async src="https://cdn.jsdelivr.net/gh/sukkaw/busuanzi@2.3/bsz.pure.mini.js"></script><span class="busuanzi-uv"><i class="fa fa-user"></i><span>访问人数 </span><span id="busuanzi_value_site_uv"></span></span><span class="separator">|</span><span class="busuanzi-pv"><i class="fa fa-eye"></i><span>浏览总量 </span><span id="busuanzi_value_site_pv"></span></span></div><div><span>&copy; 2018-2019</span><span> </span><span>SataQiu.github.io, all rights reserved</span></div></div></footer><div id="back-top"><div class="back-top-inner" title="回到顶部"><i class="fa fa-rocket"></i></div></div></div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="/js/utils.js?v=1.0.1"></script><script src="/js/img-size.js?v=1.0.1"></script><script src="/js/scroll.js?v=1.0.1"></script><script src="/js/header.js?v=1.0.1"></script><script src="/js/sidebar.js?v=1.0.1"></script><script src="/js/post.js?v=1.0.1"></script><link href="https://sataqiu.github.io/css/gitment.css" rel="stylesheet" type="text/css"><script src="https://sataqiu.github.io/js/gitment.js"></script><script>function renderGitment() {
  var gitment = new Gitment({
    id: "1563161011000",
    owner: "SataQiu",
    repo: "SataQiu.github.io",
    oauth: {
      client_id: "e402ca8a99d7da838222",
      client_secret: "77839f763908ab4edeca0ae6e9026bdfdb9e90ca"
    }
  });
  gitment.render("gitment-container")
}

if (false)
  function showGitment() {
    document.getElementById("gitment-button").style.display = "none";
    document.getElementById("gitment-container").style.display = "block";
    renderGitment();
  }
else
  renderGitment();</script></body></html>